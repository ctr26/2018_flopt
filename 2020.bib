
@online{1956AuJPh198BPage,
  title = {{{1956AuJPh}}...9..{{198B Page}} 198},
  url = {http://adsabs.harvard.edu/full/1956AuJPh...9..198B},
  urldate = {2020-04-27},
  file = {/Users/ctr26/Zotero/storage/6ZA9NEPV/1956AuJPh...9..html}
}

@online{1956AuJPh198BPagea,
  title = {{{1956AuJPh}}...9..{{198B Page}} 198},
  url = {http://adsabs.harvard.edu/full/1956AuJPh...9..198B},
  urldate = {2020-04-27},
  file = {/Users/ctr26/Zotero/storage/GWVQ6BEC/1956AuJPh...9..html}
}

@article{bracewellStripIntegrationRadio1956,
  title = {Strip {{Integration}} in {{Radio Astronomy}}},
  author = {Bracewell, R. N.},
  date = {1956-06-01},
  journaltitle = {Australian Journal of Physics},
  shortjournal = {Australian Journal of Physics},
  volume = {9},
  pages = {198},
  issn = {0004-9506},
  doi = {10.1071/PH560198},
  url = {http://adsabs.harvard.edu/abs/1956AuJPh...9..198B},
  urldate = {2020-04-27},
  abstract = {Not Available},
  file = {/Users/ctr26/Zotero/storage/3ABIGL3U/Bracewell - 1956 - Strip Integration in Radio Astronomy.pdf}
}

@article{fischlerRandomSampleConsensus1981,
  title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  shorttitle = {Random Sample Consensus},
  author = {Fischler, Martin A. and Bolles, Robert C.},
  date = {1981-06-01},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {24},
  pages = {381--395},
  issn = {0001-0782},
  doi = {10.1145/358669.358692},
  url = {https://doi.org/10.1145/358669.358692},
  urldate = {2020-04-24},
  abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
  file = {/Users/ctr26/Zotero/storage/WP5W25EX/Fischler and Bolles - 1981 - Random sample consensus a paradigm for model fitt.pdf},
  keywords = {automated cartography,camera calibration,image matching,location determination,model fitting,scene analysis},
  number = {6}
}

@article{loweDistinctiveImageFeatures2004,
  title = {Distinctive {{Image Features}} from {{Scale}}-{{Invariant Keypoints}}},
  author = {Lowe, David G.},
  date = {2004-11},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {International Journal of Computer Vision},
  volume = {60},
  pages = {91--110},
  issn = {0920-5691},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  url = {http://link.springer.com/10.1023/B:VISI.0000029664.99615.94},
  urldate = {2020-04-24},
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  file = {/Users/ctr26/Zotero/storage/ETDKAFT9/Lowe - 2004 - Distinctive Image Features from Scale-Invariant Ke.pdf},
  langid = {english},
  number = {2}
}

@inproceedings{loweObjectRecognitionLocal1999,
  title = {Object Recognition from Local Scale-Invariant Features},
  booktitle = {Proceedings of the {{Seventh IEEE International Conference}} on {{Computer Vision}}},
  author = {Lowe, D.G.},
  date = {1999-09},
  volume = {2},
  pages = {1150-1157 vol.2},
  doi = {10.1109/ICCV.1999.790410},
  abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds.},
  eventtitle = {Proceedings of the {{Seventh IEEE International Conference}} on {{Computer Vision}}},
  file = {/Users/ctr26/Zotero/storage/UQ4Q6S59/Lowe - 1999 - Object recognition from local scale-invariant feat.pdf;/Users/ctr26/Zotero/storage/SDSXX5Q3/790410.html},
  keywords = {3D projection,blurred image gradients,candidate object matches,cluttered partially occluded images,computation time,computational geometry,Computer science,Electrical capacitance tomography,feature extraction,Filters,image matching,Image recognition,inferior temporal cortex,Layout,least squares approximations,Lighting,local geometric deformations,local image features,local scale-invariant features,low residual least squares solution,multiple orientation planes,nearest neighbor indexing method,Neurons,object recognition,Object recognition,primate vision,Programmable logic arrays,Reactive power,robust object recognition,staged filtering approach,unknown model parameters}
}

@book{szeliskiComputerVisionAlgorithms2010,
  title = {Computer {{Vision}}: {{Algorithms}} and {{Applications}}},
  shorttitle = {Computer {{Vision}}},
  author = {Szeliski, Richard},
  date = {2010-09-30},
  publisher = {{Springer Science \& Business Media}},
  abstract = {Humans perceive the three-dimensional structure of the world with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem and what is the current state of the art? Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging, and for fun, consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos. More than just a source of “recipes,” this exceptionally authoritative and comprehensive textbook/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting them to produce descriptions of a scene. These problems are also analyzed using statistical models and solved using rigorous engineering techniques Topics and features:  Structured to support active curricula and project-oriented courses, with tips in the Introduction for using the book in a variety of customized courses Presents exercises at the end of each chapter with a heavy emphasis on testing algorithms and containing numerous suggestions for small mid-term projects Provides additional material and more detailed mathematical topics in the Appendices, which cover linear algebra, numerical techniques, and Bayesian estimation theory Suggests additional reading at the end of each chapter, including the latest research in each sub-field, in addition to a full Bibliography at the end of the book Supplies supplementary course material for students at the associated website, http://szeliski.org/Book/  Suitable for an upper-level undergraduate or graduate-level course in computer science or engineering, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries. Its design and exposition also make it eminently suitable as a unique reference to the fundamental techniques and current research literature in computer vision.},
  eprint = {bXzAlkODwa8C},
  eprinttype = {googlebooks},
  isbn = {978-1-84882-935-0},
  keywords = {Computers / Computer Graphics,Computers / Optical Data Processing,Computers / Software Development & Engineering / General},
  langid = {english},
  pagetotal = {824}
}


