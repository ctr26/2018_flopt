\documentclass{osa-article}
\input{preamble}
\input{glossary}

\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
   \hskip -\arraycolsep
   \let\@ifnextchar\new@ifnextchar
   \array{#1}}
\makeatother

%% Select the journal you're submitting to
%% oe, boe, ome, osac, osajournal
\journal{osajournal}
% Key:
% Express journals must have the correct journal selected:
% {oe} Optics Express
% {boe} Biomedical Optics Express
% {ome} Optical Material Express
% {osac} OSAC Continuum
% Other OSA journals may use:
% {osajournal} Applied Optics, Advances in Optics and Photonics, Journal of the Optical Society of America A/B, Optics Letters, Optica, Photonics Research

% Uncomment if submitting to Photonics Research.
% ONLY APPLICABLE FOR \journal{osajournal}
% \setprjcopyright

% Set the article type
\articletype{Research Article}
% Note that article type is not required for Express journals (OE, BOE, OME and OSAC)

\begin{document}

\title{Frame Localisation Optical Projection Tomography}

\author{Craig Russell,\authormark{1*,2}, \author{Pedro P Vallejo\authormark{1}}, Eric Rees,\authormark{1}}

\address{Department of Chemical Engineering and Biotechnology, University of Cambridge,\authormark{1}}
\address{National Physical Laboratory, \authormark{2}}
\email{\authormark{*}craig.russell@npl.co.uk} %% email address is required

% \homepage{http:...} %% author's URL, if desired

%%%%%%%%%%%%%%%%%%% abstract %%%%%%%%%%%%%%%%
\begin{abstract}
  We present a tomographic reconstruction algorithm, which is applied to Optical Projection Tomography (OPT) [1] images, that is robust to mechanical jitter and systematic angular and spatial drift.
  OPT relies on precise mechanical rotation and is less mechanically stable than large-scale CT scanning systems, leading to reconstruction artefacts.
  The algorithm uses multiple (5+) tracked fiducial beads to recover the sample pose and the image rays are then back-projected at each orientation.
  The quality of the image reconstruction using the proposed algorithm shows an improvement when compared to the Radon transform.
  Moreover, when adding a systematic spatial and angular mechanical drift, the reconstruction shows a significant improvement over the Radon transform.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%  body  %%%%%%%%%%%%%%%%%%%%%%%%%%

% \section{Frame localisation optical projection tomography}

% % \epigraph{\emph{Pascale Sauvage}}{--- Pablo Vallejo}
%
% % Volumetric imaging can also be achieved by rotating a sample and %reconstructing tomographically.
% % tomographically reconstructing the 3D distribution of a signal (scattering, absorption or luminosity) within the specimen.
% %Orthogonal imaging schema can be replaced with pass through imaging provide samples are sufficiently transparent.
% %Instead of scanning these samples laterally one can rotate their sample and reconstruct a full three dimensional image.
% %As tomographic technology has been shrunk to the millimeter scale, errors induced by hardware become apparent.
% Accurate %reconstructions of volumes rely on
% tomographic reconstruction relies
% heavily on precision movement and rotation.
% %This chapter addresses a key downside in traditional approaches to performing full three dimensional reconstructions tomographically.
% Here an algorithm will be presented that relies exclusively on multiple (4+) tracked fiducial beads to enable accurate reconstruction even with systematic mechanical drift.
% It will be demonstrated on ground truth simulated testcard image data with motion errors compounded onto the tomographic rotation.
% These motion errors will include systematic mechanical drift, giving a spiral path; and angular drift giving precession.

% \section{Rotational computer tomography in microscopy}

%Well establishjed
%Three-dimensional imaging of anatomy in thick biological samples provides valuable data for developmental biology studies.
%Tomographic techniques that generate 3D reconstructions from 2D images such as computed tomography (CT) and magnetic resonance imaging (MRI) are essential in medical applications to visualize morphology in large tissues and organs.
%CT and especially micro-CT can achieve micron-scale resolution using certain contrast agents, however the high doses of radiation used make this unsuitable for repeated experiments on a biological sample.
%Micro-MRI can also achieve resolution in the micron scale, however the cost and size of MRI instruments can be prohibitive for many applications[21].
%Furthermore, neither of these techniques can exploit the plethora of information that can be extracted through fluorescence microscopy.

Sharpe~\emph{et. al} proposed \gls{OPT}~\cite{sharpeOpticalProjectionTomography2002}
using visible light to image transparent or translucent mesoscopic samples, with micrometer resolution.
\gls{OPT} addresses the scale gap between photographic techniques (for samples typically larger than \SI{10}{\milli\meter}), and light microscopy techniques (samples smaller than \SI{1}{\milli\meter}) to image biological samples in the \SIrange{1}{10}{\milli\meter} range.
% \gls{OPT} is non-invasive optically but may require specialist invasive preparation for its samples.

%Optical Projection Tomography was first proposed by Sharpe in 2002 [30]; it uses visible light to image and create volumetric data of transparent (naturally or artificially) mesoscopic objects (1 - 10 mm) at micron-level resolution.

\gls{OPT} is based on computerised tomography techniques~\cite{kakPrinciplesComputerizedTomographic2001} in which a set of projections of a specimen are imaged as the specimen travels through a full rotation.
Typically, a Radon transform is then used to transform this set of images into a 3D image stack in Cartesian coordinates (\(X,Y,Z\)).
%A cross-sectional stack of slices from the original object is reconstructed using a back-projection algorithm from the projection images.
The \gls{Radon transform} relies heavily on the assumption of circular motion with constant angular steps about a vertical axis.
This work presents an improved reconstruction algorithm that is robust to spatial and angular mechanical drifts during acquisitions, as well as to inconsistent angular steps.
The proposed algorithm triangulates points between image pairs to extract camera pose using the theoretical framework used in stereoscopic imaging. %TODO reword

% There are two imaging modalities for \gls{OPT}, \gls{eOPT} and \gls{tOPT}.
% In \gls{eOPT}, a fluorescent sample is excited using an illumination source off axis to the detection, similar to \gls{light-sheet} but the entire \gls{depth of field} of the detection of objective is illuminated.
% % without the excitation being shaped into a sheet.
% Scattered illumination photons are rejected at the detector using an appropriate filter.
% In tOPT, a white-light source with a diffuser and a collimator is placed along the optical axis to provide near-collimated, uniform illumination onto the sample for transmission to a detector opposite (see \figurename~\ref{fig:OPT_digram}).
% Each \gls{photosite} at the detector corresponds to a ray that has passed through the sample and been attenuated by the sample.
% The \gls{eOPT} and \gls{tOPT} modes can work in unison to provide contextual information, with the transmission images indicating overall structure (optical density of absorption or scattering) which can be supplemented by the fluorescent signal from a label of interest.
%
% \begin{figure}
%   \centering
%   \includegraphics{./figures/OPT_digram}
%   \caption[Principle of OPT]{Principle of \gls{OPT}, a respective rotation between the sample and the detector illumination pair is iterated.
%   The volumetric image is later reconstructed from the set of detections (1/2D).}
%   \label{fig:OPT_digram}
% \end{figure}


\section{Stereoscopic imaging}

\begin{figure}
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics{./figures/coordinate_system}
        \caption[Coordinate system]{Coordinate system describing a camera with an associated image plane one focal distance \(f\) away, imaging an object at point \(\gls{X}\).
        }\label{fig:coordinate_system_flopt}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.48\textwidth}
      \centering
      \includegraphics{./figures/OPT_digram}
      \caption[Principle of OPT]{From an angle \(\theta \), an object \(f(X,Y)\) and its projection \(P_\theta(\nu)\) are known.}\label{fig:OPT_digram}
      %{Principle of \gls{OPT}, a respective rotation between the sample and the detector illumination pair is iterated.
      % The volumetric image is later reconstructed from the set of detections (1/2D).}
    \end{subfigure}
    \caption[Coordinates and \gls{OPT}]{\gls{X_c} = \((X_c,Y_c,Z_c)\) is the camera-centered coordinate point in 3D space.
            \gls{X} = \((X,Y,Z)\) is the world coordinate point in 3D space.
            \gls{p} = \((x,y,f)\) is the ray vector to point of image plane.
            \gls{x} = \((x,y)\) is the image plane coordinates.
            \gls{w} = \((u,v)\) are the pixel coordinates (not shown) corresponding to the point \gls{x}.
            The optical axis travels along the \(Z_c\) axis through the image plane.}
    % \label{fig:aa}
\end{figure}
\begin{figure}
  \centering
  \includegraphics{./figures/epi-polar-geom}
  \caption[Epi-polar geometry described for two adjacent views]{
  Epi-polar geometry described for two adjacent views (or cameras of a scene).
  Coordinates as expressed in \figurename~\ref{fig:coordinate_system_flopt} with prime notation (\('\)) denoting the additional right camera view.
  Transforming from right to left camera-centered coordinates (\gls{X_c'} to \gls{X_c}) requires a rotation (\gls{R}) and a translation (\gls{T}).
  }\label{fig:epi-polar-geom}
\end{figure}

%\subsection{Projective geometry}

%Camera imaging is governed by projective geometry
%Parallel lines project onto a camera will have a vanishing point at the horizon.

%\subsection{Camera projections}

When the features or fiducial markers in one view are uniquely identifiable, the stereoscopic imaging of scenes allows for the triangulation of individual features in three dimensional space (known as world points), see Figure~\ref{fig:epi-polar-geom} for the coordinate system which describes this geometry. %(such as fluorescent beads).
Triangulation requires that each feature is detected in both images of a stereo imaging system and for these detections to be correctly associated with one another.
This is known as the correspondence problem.
Various methods exist to ensure that features are detected from image data and accurately associated between two cameras or views \cite{?} and the properties of scale-independent features and their surrounding pixel environment in one image can thus be matched to a similar feature in a second image.

Coordinates in two adjacent views with a common epi-pole (see Figure~\ref{fig:epi-polar-geom}) are related by the essential matrix (\gls{Essential}) for uncalibrated cameras and the fundamental matrix (\gls{F}) for calibrated cameras.
Their properties are described by:
\begin{gather}
\gls{p'}^T \gls{Essential} \gls{p} = 0 \label{eq:pEp}\\
\gls{Essential} = \gls{K'}^T \gls{F} \gls{K} %= \gls{T_x} \gls{R} = \mathbf{U}\Lambda \mathbf{V}^T%\gls{R} = U\LambdaV^T\\
\end{gather}
Where \(\gls{K}\) is a matrix that converts image plane coordinates to camera pixel coordinates and where \gls{p} refers to a point in the image plane.

\section{The proposed algorithm}

%The rotation may also not be orthogonal to the plane of detection.
The motion of a rotating sample, as in an \gls{OPT} acquisition, with a transformation matrix (\( \begin{bmatrix}[c|c] \gls{R} & \gls{T} \end{bmatrix}\)) in view of a fixed camera is analogous to the motion of a camera with the inverse transformation matrix around the scene. %TODO reword
% The shift of a camera around a scene separated by a transformation matrix (\( \begin{bmatrix}[c|c] \gls{R} & \gls{T} \end{bmatrix}\)) is analogous to transforming the sample in the fixed view of an imaging detector, as in an \gls{OPT} acquisition.
During an ideal \gls{OPT} acquisition, a marker will appear to follow an elliptical path in the \(xy\) image plane. For the volume reconstruction procedure, there is a fitting step to recover the path of the fiducial marker, which is used to correct the sinogram before applying the inverse \gls{Radon transform}. This type of reconstruction not only ignores any mechanical jitter of the sample, but also any affine, systematic, mechanical drift (in \(X,Y,Z,\theta,\phi,\psi \)). %TODO is this true?
Using two adjacent images of a scene, separated by some rotation and translation, world points in 3D space may be triangulated within the scene given the rotational and translational matrices of the respective camera views.

% The inverse is also possible, given a sufficient number of known fiducial points in a scene the translation and rotation matrices can be recovered.

% The recovery of a more exact description of the motion of the scene can eliminate any need for a fitting and may recover and correct for drift, as well as eliminate any mechanical jitter.
% Errors may however then be introduced from fiducial markers mechanically slipping and localisation errors.
% Fiducial markers in this sense refer to an accurately locatable marker common through different views in a sample.

Once a sufficient amount of fiducial markers are reliably tracked from the first to the second image, either of the \glslink{fundamental matrix}{fundamental} or \glslink{essential matrix}{essential} matrices can be computed. Using the factorisation of one of these matrices, between each adjacent view of a rotating scene, the translation and rotational matrices can be recovered.
% Here we will discuss a reconstruction using \gls{F} but the same principle applies for \gls{Essential} and \gls{H}.

% Here are two ways of reconstructing using the fundamental matrix as described above.
To reconstruct the image, we compute \gls{F} for the current image and the first image using 5 or more fiducial markers; having additional beads helps to remove ambiguity and increase confidence in \gls{F}.
Once \gls{F} is calculated, it is decomposed into \(\gls{R}_n\) and \(\gls{T}_n\) between each view \(n\) and \(n+1\).
The image at view \(n+1\) is then back projected along the virtual optical axis within a virtual volume where the sample will be reconstructed.
The size of this back projection and virtual volume is chosen to be suitably large, preventing the loss of important data.
% Then, all the prior rotation and translation matrices are serially multiplied from \(\begin{bmatrix}[c|c] \gls{R}_0&\gls{T}_0 \end{bmatrix}\) until \(\begin{bmatrix}[c|c] \gls{R}_n&\gls{T}_n \end{bmatrix}\) % \([R_n|T_n] \)
% , this final matrix is inverted and applied to the back projected volume.
The recovered transformation matrices are then matrix inverted and applied to the back projection of the image to realign the rays in the volume to their respective source positions. %TODO hard sentence.
% This process is repeated for every angle the sum of these ray projection volumes is filtered using a high-pass filter; here a \gls{Ram-Lak filter} is used.
% \footnote{Linear real (amplitude) ramp filter in Fourier space}. %: \(|v|\)}
% By producing a series of transformation matrices from adjacent acquisitions, errors compound and the reconstruction of volumes degrades with more projections, see \figurename~\ref{fig:irandons}.

\begin{figure}
    \centering
    \begin{subfigure}[t]{\textwidth}
      \centering
      \includegraphics{./figures/flopt_algorithm_forward}
      \caption{Forward model}\label{fig:flopt_algorithm_forward}
    \end{subfigure}\\\vspace{\abovecaptionskip}
    \begin{subfigure}[t]{\textwidth}
      \centering
      \includegraphics{./figures/flopt_algorithm}
      \caption{Reconstruction method, solving the inverse problem.}\label{fig:flopt_algorithm_inverse}
    \end{subfigure}
    \caption[Simulation of \gls{OPT} data incorporating rotational and translational offsets, and the proposed reconstruction algorithm]{
    % Two dimensional representation of the reconstruction algorithm.
    The simulation of \gls{OPT} data incorporating rotational and translational offsets, and the proposed reconstruction algorithm.
    (\subref{fig:flopt_algorithm_forward}): The \(n\) projections of the object (\(\Sigma \)), at rotation (\(\gls{R}_1\) to \(\gls{R}_n\)) and translation (\(\gls{T}_1\) to \(\gls{T}_n\)), produces \(n\) frames of image data.
    During the \gls{OPT} measurement, \(n\) projections of the object \(\Sigma \) are observed with rotations \(\gls{R}_1\) to \(\gls{R}_n\) and corresponding translations \(\gls{T}_1\) to \(\gls{T}_n\) where the translations account for imperfect alignment.
    (\subref{fig:flopt_algorithm_inverse}): In the reconstruction algorithm, the rotational and translational matrices are recovered (\(\gls{R}_1'\) to \(\gls{R}_n'\) and \(\gls{T}_1'\) to \(\gls{T}_n'\)) from triangulation of the fiducial markers.
    These transformation matrices are then used to obtain a contribution to the volumetric reconstruction from each observed frame and the summated reconstruction is assembled from the \(n\) frames.
    The now realigned back projections are summed to produce an unfiltered back projection.
    % and inversely applied
    % to align back project the datasets,
    The transformation matrices are shown in augmented form using homogenous coordinates.
    }\label{fig:flopt_algorithm} %TODO tidy
\end{figure}

% The second approach is robust against compound errors but an additional programatic step is needed to know which beads in the first image correspond to beads in the \(n^{\text{th}}\) image.
% This can be is achieved using tracking and momentum particle tracking algorithms, though confounding issues can arise i.e.~if a particle orbits too far away from the imaging plane or occlusions occur.

In both cases, a decomposed \gls{F} matrix will produce four possible transformation pairs (\gls{R},\gls{T}; \gls{R},-\gls{T}; -\gls{R},\gls{T}; -\gls{R},-\gls{T}).
Once the transformation matrix between the current view (\(n\)) and the first view is calculated, the proceeding transformation matrices are then easily chosen by similarity to the previously collected matrix and general direction of motion.
An example of this type of selection would be:
\begin{align}
\min_{I(n)}\left[I(n) = \left(\begin{bmatrix}[c|c] \gls{R}_n&\gls{T}_n \end{bmatrix} - \begin{bmatrix}[c|c] \gls{R}_{n-1}&\gls{T}_{n-1} \end{bmatrix}\right)^2\right]
\end{align}
To find the correct matrix between the \(n=0\) and \(n=1\) orientations, each of the four matrices are compared to an ideal matrix which is composed using \emph{a priori} knowledge of the likely angle of rotation of the system's imaging properties.

\section{Verification of the proposed algorithm}

To verify the validity and quality of the proposed reconstruction algorithm, the image of Lena, superposed with an orthogonal image of Cameraman, is used as a testcard volume.
Virtual fiducial beads are dispersed in the volume to track the rotation and translation of the image and shown in \figurename~\ref{fig:raw_input}.
The reference image is then rotated through \SI{128} angles over \(2\pi \) radians and projected along the \(Y\) axis, then an image slice in (\(X,Y\)) is taken to create a single line projection, shown three dimensionally in \figurename~\ref{fig:recon_iterative}.
This is repeated for each angle,  with each line projection stacked to create a sinogram.%, see \figurename~\ref{fig:sinogram_stretch}.

% \begin{figure}
%   \centering
%   \hfill
%   \begin{subfigure}[t]{0.3\textwidth}
%     \includegraphics[width=\textwidth]{./figures/results/no_helix/rawinput_colour}
%     \caption{Raw input for OPT simulations, Lena.}
%     \label{fig:raw_input}
%   \end{subfigure}\hfill
%   \begin{subfigure}[t]{0.3\textwidth}
%     \includegraphics[width=\textwidth]{./figures/results/no_helix/sinogram_stretch}
%     \caption{Image of Lena (\figurename~\ref{fig:raw_input}) after rotation and projection in 2D, giving the sinogram.}
%     \label{fig:sinogram_stretch}
%   \end{subfigure}
%   \hfill
%   \label{fig:rawinputs}
%   \caption{Reference images for OPT reconstruction.}
% \end{figure}

\begin{figure}
    % \begin{subfigure}[t]{\linewidth}
        \centering
        \includegraphics[width=0.4\textwidth]{./figures/ortho_3d_correct}
        \caption{Ground truth 3D object for reconstruction, based on the Cameraman and Lena testcard images.}\label{fig:ortho_3d_correct}
    % \end{subfigure}
\end{figure}
\begin{figure}
% \ContinuedFloat{}
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/0/xy}\caption{Raw\\Frame (\(n\)): 0\\View: (\(X,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/0/xy_recon}\caption{Reconstructed\\Frame (\(n\)): 0\\View: (\(X,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/0/zx}\caption{Raw\\Frame (\(n\)): 0\\View: (\(Z,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/0/zx_recon}\caption{Reconstructed\\Frame (\(n\)): 0\\View: (\(Z,Y\))}
    \end{subfigure}
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/1/xy}\caption{Raw\\Frame (\(n\)): 1\\View: (\(X,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/1/xy_recon}\caption{Reconstructed\\Frame (\(n\)): 1\\View: (\(X,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/1/zx}\caption{Raw\\Frame (\(n\)): 1\\View: (\(Z,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/1/zx_recon}\caption{Reconstructed\\Frame (\(n\)): 1\\View: (\(Z,Y\))}
    \end{subfigure}
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/dots/xy}%\caption{Raw data. Frame (\(n\)): , View: \(xy\)}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/dots/xy_recon}%\caption{Reconstructed\\Frame (\(n\)):0, View:\(xy\)}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/dots/zx}%\caption{Raw data. Frame (\(n\)): , View: \(zy\)}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/dots/zx}%\caption{Reconstructed\\Frame (\(n\)):, View:\(zx\)}
    \end{subfigure}
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/31/xy}\caption{Raw\\Frame (\(n\)): 31\\View: (\(X,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/31/xy_recon}\caption{Reconstructed\\Frame (\(n\)): 31\\View: (\(X,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/31/zx}\caption{Raw\\Frame (\(n\)): 31\\View: (\(Z,Y\))}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.2\linewidth}
        \centering
        \includegraphics[width=\textwidth]{./figures/results/3D_python/no_drift/31/zx_recon}\caption{Reconstructed\\Frame (\(n\)): 31\\View: (\(Z,Y\))}
    \end{subfigure}
    \caption[A 3D test-volume of two orthogonal and different testcard images, was used to verify the reconstructive capabilities of the proposed algorithm]{
    A 3D test-volume of two orthogonal and different testcard images, from \figurename~\ref{fig:ortho_3d_correct}, was used to verify the reconstructive capabilities of the proposed algorithm.
    The projected image data (b),~(h),~(j) and (d),~(h),~(l), were used to iteratively generate reconstructions where the \(n^\text{th}\) reconstruction incorporates all the information from observation 0 to \(n\).
    The results are unfiltered for clarity of demonstrating the iterative reconstruction, which is applied in \figurename~\ref{fig:flopt_filter}.
    }\label{fig:recon_iterative}
\end{figure}

In the standard approach for \gls{OPT} reconstruction, the sinogram undergoes the inverse \gls{Radon transform}, as shown in \figurename~\ref{fig:iradon_nofilter}, followed by post-filtering, as shown in \figurename~\ref{fig:iradon_filter}.
This step is substituted for the proposed algorithm; in \figurename~\ref{fig:flopt_comparison_line_profile} the two techniques are compared for ideal conditions of smooth, predictable rotation.
The proposed algorithm produces %(see )
a faithful reconstruction on the original image, as shown in \figurename~\ref{fig:flopt_filter}. %with some minor deviations.
% there is good overlap between the two,
\figurename~\ref{fig:flopt_histogram} illustrates the strong overlap of the images produced by the new algorithm and the \gls{Radon transform} when considering the histogram of the absolute pixel-wise difference between the original source image and the respective reconstructions.
The proposed algorithm generates lower deviance from the source image than the Radon transform.
The mean square errors (\gls{MSE}, see Equation~\eqref{eq:mse}) of the new algorithm and the \gls{Radon transform} are \SI{15.01}{\percent} and \SI{14.84}{\percent}, respectively, see \figurename~\ref{fig:flopt_histogram} for a histogram of a pixel-wise comparison.
%, see \figurename~\ref{fig:flopt_histogram}

\begin{align}
    \operatorname{\gls{MSE}}=\frac{1}{n}\sum_{i=1}^n{(Y_i-\hat{Y_i})}^2 \label{eq:mse} % \intertext{Where \(\hat{Y_i}\) is the ith value and Y_i }
\end{align}

\begin{figure}
  \centering
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/results/comparison_line_profile}
    % \caption[Line profile comparison of the standard and new algorithms]{Line profile comparison of the reconstruction of a reference image computationally rotated, projected and reconstructed using the standard \gls{Radon transform} and the new proposed algorithm.}
    \caption{}\label{fig:flopt_comparison_line_profile}
  \end{subfigure}\quad
 \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/results/flopt_histogram}
    % \caption[Histogram of pixel values compared between reconstructions using flOPT and the \gls{Radon transform}]{Histogram of of pixel values compared between reconstructions using flOPT and the \gls{Radon transform}.
    % The shift of the histogram to towards overall lower deviance from the source image suggests the flOPT algorithm out performs the \gls{Radon transform}}\label{fig:flopt_histogram}
    \caption{}\label{fig:flopt_histogram}
  \end{subfigure}\\
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./figures/results/correlation_helicity}
    % \caption[Comparison of standard and proposed OPT reconstruction algorithms for acquisitions with drift]{%2D correlation of the source image shows that flOPT does not degrade under systematic drift compared to s.
    % Comparison of standard and proposed \gls{OPT} reconstruction algorithms for acquisitions with drift.
    % 2D image correlation of the ground truth and the reconstruction shows that the proposed flOPT algorithm does not degrade with systematic drift, whereas reconstruction using the standard \gls{Radon transform} is severely degraded.
    % }
    \caption{}\label{fig:helical_comparison}
  \end{subfigure}
  \caption{
  (\subref{fig:flopt_comparison_line_profile}), Line profile comparison of the reconstruction of a reference image computationally rotated, projected and reconstructed using the standard \gls{Radon transform} and the new proposed algorithm.
  (\subref{fig:flopt_histogram}), Histogram of of pixel values compared between reconstructions using the new proposed flOPT algorithm and the \gls{Radon transform}.
  The shift of the histogram to towards overall lower deviance from the source image suggests the flOPT algorithm outperforms the \gls{Radon transform}
  (\subref{fig:helical_comparison}): Comparison of standard and proposed \gls{OPT} reconstruction algorithms for acquisitions with drift.
  2D image correlation of the ground truth and the reconstruction shows that the proposed flOPT algorithm does not degrade with systematic drift, whereas a reconstruction using the standard \gls{Radon transform} is severely degraded.}
\end{figure}

%However, the proposed algorithm fairs worse in terms of contrast compared to a \gls{Radon transform}.

The more challenging case of a sample drifting systematically along the \(X\) axis, with a constant velocity, was then considered. This drift produced a helical path of a single fiducial within the sample, see \figurename~\ref{fig:flopt_helix_sinogram}.
In \figurename~\ref{fig:unfilttered_reconstruction_helix_iradon}, the \gls{Radon transform} fails to produce a recognisable reproduction of the test image with the addition of a slight helicity to the rotation.
The proposed algorithm produces an equivalent result to that of a sample rotating without any systematic drift, see \figurename~\ref{fig:iradon_filter}.
In \figurename~\ref{fig:helical_comparison} the respective reconstructions from each algorithm were compared, as before, while the helical shift was incremented.
See \figurename~\ref{fig:flopt_helix_sinogram} for a sinogram of a sample wherein a helical shift has been induced.
When using correlation as a metric of reproduction quality, the new algorithm fares slightly worse at zero helicity, with \SI{94}{\percent} correlation compared to the \gls{Radon transform} at \SI{96}{\percent}.
As expected, the \gls{Radon transform} rapidly deteriorates once a systematic drift is applied, whereas the new algorithm maintains the quality of the reconstruction, see \figurename~\ref{fig:helical_comparison}.

\begin{figure}
  \centering
  \hspace*{\fill}
 \begin{subfigure}[t]{0.3\textwidth}
   \begin{tikzpicture}[node distance=0cm]
     \node (img) {\includegraphics[width=0.8\textwidth]{./figures/results/helix/topdown_bead_paths}};
      \node[below=of img] {\(X\)};
      \node[left=of img,rotate=90,yshift=0.2cm] {\(Y\)};
   \end{tikzpicture}
   \caption{Top down views (\(X,Y\)) of the source image with the fiducial paths marked.}\label{fig:topdown_bead_paths}
 \end{subfigure}\hfill
 \begin{subfigure}[t]{0.3\textwidth}
   \begin{tikzpicture}[node distance=0cm]
     \node (img) {\includegraphics[width=0.8\textwidth]{./figures/results/helix/sinugram_stretch}};
      \node[below=of img] {\(v\)\vphantom{\(X\)}};
      \node[left=of img,rotate=90,yshift=0.2cm] {\(n\)};
   \end{tikzpicture}
   \caption{Sinogram (\(v,n\)) of a sample whose axis of rotation has a systematic drift}\label{fig:flopt_helix_sinogram}
 \end{subfigure}\hspace*{\fill}
  \\\vspace{\abovecaptionskip}
  \hspace*{\fill}
  \begin{subfigure}[t]{0.3\textwidth}
    \begin{tikzpicture}[node distance=0cm]
      \node (img) {\includegraphics[width=0.8\textwidth]{./figures/results/helix/unfilttered_reconstruction_helix_iradon}};
       \node[below=of img] {\(X\)};
       \node[left=of img,rotate=90,yshift=0.2cm] {\(Y\)};
    \end{tikzpicture}
    \caption{Unfiltered reconstruction using a \gls{Radon transform}.}\label{fig:unfilttered_reconstruction_helix_iradon}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.3\textwidth}
    \begin{tikzpicture}[node distance=0cm]
      \node (img1) {\includegraphics[width=0.8\textwidth]{./figures/results/helix/filtered_recon_helix}};
       \node[below=of img1] {\(X\)\vphantom{\(X\)}};
       \node[left=of img1,rotate=90,yshift=0.2cm] {\(Y\)};
    \end{tikzpicture}
    \caption{Filtered reconstruction using the new algorithm.}\label{fig:filtered_recon_helix}
  \end{subfigure}
   \hspace*{\fill}
   % \caption{}
  \caption{Comparison of the two reconstructions under sample imaging with a systematic drift, in 3D though represented here in 2D.}\label{fig:flopts}
\end{figure}

\subsection{Recovery of R and T using matrix decomposition}

To quantitatively verify that the matrix decomposition technique was valid and robust, the accuracy of the reproduction of \gls{R} and \gls{T} was tested directly.
The original \gls{R} and \gls{T} matrices were computed and compared to \gls{R} and \gls{T} generated from matrix decomposition. This absolute difference was computed element-wise in each matrix and then an average for each matrix was taken.
Overall, the worst-case scenario produced a percentage error of \SI{2}{\percent} (see \figurename~\ref{fig:pc_sum_decompose} for full statistics).
The accuracy of the calculated \gls{R} and \gls{T} deteriorated when adding in additional degrees of combined movement, but with no correlation between the degree of helicity and the error produced.
% but the severity of this movement appeared to no trending effect.
The translation matrix (\gls{T}) was consistently more accurately reproduced, which is likely due to it having fewer available degrees of freedom.
% Consistently the translational matrix (\gls{T}) was more accurately reproduced, this is likely due to there being fewer of degrees of freedom for errors to spread over.

%The images produced are a more faithful reproduction of the source image as the degree of helicity is increased.
%This effect may be due to the additional sampling induced by adding another degree of movement, that is the systematic drift.

%Textwidth is \the\textwidth


\begin{figure}
  \centering
    \begin{subfigure}[t]{0.5\textwidth}
      \captionsetup{width=0.8\textwidth}
      \centering
      \includegraphics[width=\textwidth]{./figures/results/helix/decompose/pc_sum_rot_alpha}
      \caption{Rotation matrix, with angular drift in \(\alpha \)}\label{fig:pc_sum_rot_alpha}
    \end{subfigure}\hfill
    \begin{subfigure}[t]{0.5\textwidth}
      \captionsetup{width=0.8\textwidth}
      \centering
      \includegraphics[width=\textwidth]{./figures/results/helix/decompose/pc_sum_trans_alpha}
      \caption{Translation matrix, with angular drift in \(\alpha \)}\label{fig:pc_sum_trans_alpha}
    \end{subfigure}
    \bigskip
        \begin{subfigure}[t]{0.5\textwidth}
          \captionsetup{width=0.8\textwidth}
          \centering
          \includegraphics[width=\textwidth]{./figures/results/helix/decompose/pc_sum_rot_tx}
          \caption{Rotation matrix, with helical drift in \(x\) only}\label{fig:pc_sum_rot_tx}
        \end{subfigure}\hfill
        \begin{subfigure}[t]{0.5\textwidth}
          \captionsetup{width=0.8\textwidth}
          \centering
          \includegraphics[width=\textwidth]{./figures/results/helix/decompose/pc_sum_trans_tx}
          \caption{Translation matrix, with helical drift in \(x\) only}\label{fig:pc_sum_trans_tx}
        \end{subfigure}
    \bigskip
        \begin{subfigure}[t]{0.5\textwidth}
          \captionsetup{width=0.8\textwidth}
          \centering
          \includegraphics[width=\textwidth]{./figures/results/helix/decompose/pc_sum_rot_both}
          \caption{Rotation matrix, with angular drift in \(\alpha \) and helical drift in \(x\)}\label{fig:pc_sum_rot_both}
        \end{subfigure}\hfill
        \begin{subfigure}[t]{0.5\textwidth}
          \captionsetup{width=0.8\textwidth}
          \centering
          \includegraphics[width=\textwidth]{./figures/results/helix/decompose/pc_sum_trans_both}
          \caption{Translation matrix, with angular drift in \(\alpha \) and helical drift in \(X\)}\label{fig:pc_sum_trans_both}
        \end{subfigure}
          \caption[Box plots demonstrating that the rotational and translations matrices can be recovered accurately from fiducial marker positions]{Box plots demonstrating that the rotational and translations matrices can be recovered accurately from fiducial marker positions.
          Panels~(\subref{fig:pc_sum_rot_alpha}) and~(\subref{fig:pc_sum_trans_alpha}) introduce an angular drift during rotation, to an observer at the detector this would appear as a tip of the sample towards them, causing precession.
          Panels~(\subref{fig:pc_sum_rot_tx}) and~(\subref{fig:pc_sum_trans_tx}) introduce a lateral drift in \(X\) causing a helical path to be drawn out.
          Panels~(\subref{fig:pc_sum_rot_both}) and~(\subref{fig:pc_sum_trans_both}) combine the two effects.
          In all cases, the percentage error introduced by the the addition of undesirable additional movements was on the order of \SI{<2}{\percent}.
          }\label{fig:pc_sum_decompose}
\end{figure}

\section{Discussion}

A new algorithm for reconstructing OPT data has been demonstrated.
The new algorithm uses multiple fiducial markers to recover the matrix which describes the rotation and translation of the sample.
The quality of the reconstructions shows a slight improvement when compared to the standard \gls{Radon transform}, with a great effect when a systematic drift is introduced.
The accuracy of the decomposition of \gls{F} into \gls{R} and \gls{T} was compared to the ground truth matrices.
The element-wise absolute difference \(\left(\frac{x-y}{2(x+y)}\right)\) of each matrix was averaged across the matrix for \gls{R} and \gls{T}.
In the worst-case scenario, a maximum of \SI{2}{\percent} average absolute difference was found between ground truth and recovered matrices,
% When comparing the
% expected matrices to the recovered matrices a
% ground truth matrices to the recovered matrices were compared using the average of the element-wise using square differences
% peak of \SI{2}{\percent} difference is found between the two when considering worst case scenarios;
suggesting that the technique is robust to various forms of drift and general instability.
Such an algorithm could be used to minimise ghosting effects seen in real samples, particularly in samples where slipping is likely to occur, such as in gels or in cheaper \gls{OPT} systems which tend to be more mechanically unstable and imprecise.

\section{Future work}

The proposed algorithm relies on triangulation between two view points.
% In this work the two view points refer to the image at frames \(n\) and \(n+1\).
However, it is possible to use three separate views %(frames \(n\), \(n+1\) and \(n+2\))
to reconstruct a scene, one such approach being quaternion tensors \cite{?}.
Working with tensors is more complex, but a future iteration of the algorithm presented here may benefit from using three views to provide a more accurate transformation matrix.
Beyond three views, there is currently no mathematical framework for four or more views.
If such tools were to be developed, it may be possible to have the algorithm described above be a non-iterative, single-shot reconstruction from pixels to voxels.

% In computer vision, scenes often do not contain known fiducial marks and so such marks are found between views.
Fiducial markers could also be extracted from the image texture alone, circumventing the need for for the additional beads embedded in the sample.
To find such correspondences, points with similar local texture are found and matched in between each image using standard algorithms such as SIFT~\cite{?} and RANSAC~\cite{?}. %, many of these such correspondences are found
This was attempted in this work, however, the errors introduced into the transformation matrices make this approach currently inviable.
% This technique is only valid for views with small angles between them, as would be found in \gls{OPT}.
\pagebreak
%
% \section{Introduction}
% Adherence to the specifications listed in this template is essential for efficient review and publication of submissions. Proper reference format is especially important (see Section \ref{sec:refs}).
%
% \section{Multiple corresponding authors}
%
% There are two options for indicating multiple corresponding authorship, and they are formatted quite differently. The first format would be as follows and uses an asterisk to denote one of the authors:
%
% \begin{verbatim}
% \author{Author One\authormark{1,3} and Author Two\authormark{2,4,*}}
%
% \address{\authormark{1}Peer Review, Publications Department,
% Optical Society of America, 2010 Massachusetts Avenue NW,
% Washington, DC 20036, USA\\
% \authormark{2}Publications Department, Optical Society of America,
% 2010 Massachusetts Avenue NW, Washington, DC 20036, USA\\
% \authormark{3}xyz@osa.org}
%
% \email{\authormark{*}opex@osa.org}
% \end{verbatim}
%
% This format will generate the following appearance:
%
% \medskip
%
% \author{Author One\authormark{1,3} and Author Two\authormark{2,4,*}}
%
% \address{\authormark{1}Peer Review, Publications Department,
% Optical Society of America, 2010 Massachusetts Avenue NW,
% Washington, DC 20036, USA\\
% \authormark{2}Publications Department, Optical Society of America,
% 2010 Massachusetts Avenue NW, Washington, DC 20036, USA\\
% \authormark{3}xyz@osa.org}
%
% \email{\authormark{*}opex@osa.org}
%
% \medskip
%
% The second format forgoes the asterisk and sets all email addresses equally within the affiliations. Please note that this format does not use the \verb+\email{}+ field at all.
% \begin{verbatim}
% \author{Author One\authormark{1,3} and Author Two\authormark{2,4}}
%
% \address{\authormark{1}Peer Review, Publications Department,
% Optical Society of America, 2010 Massachusetts Avenue NW,
% Washington, DC 20036, USA\\
% \authormark{2}Publications Department, Optical Society of America,
% 2010 Massachusetts Avenue NW, Washington, DC 20036, USA\\
% \authormark{3}xyz@osa.org\\
% \authormark{4}opex@osa.org}
% \end{verbatim}
%
% This format will generate the following appearance:
%
% \medskip
%
% \author{Author One\authormark{1,3} and Author Two\authormark{2,4}}
%
% \address{\authormark{1}Peer Review, Publications Department,
% Optical Society of America, 2010 Massachusetts Avenue NW, Washington, DC 20036, USA\\
% \authormark{2}Publications Department, Optical Society of America, 2010 Massachusetts Avenue NW, Washington, DC 20036, USA\\
% \authormark{3}xyz@osa.org\\
% \authormark{4}opex@osa.org}
% \medskip
% These are the preferred
% %express journal
% formats for multiple corresponding authorship, and either may be used.
%
%
% The abstract should be limited to approximately 100 words.
% %It should be an explicit summary of the paper that states the problem, the methods used, and the major results and conclusions. It also should contain the relevant key words that would allow it to be found in a cursory computerized search.
% If the work of another author is cited in the abstract, that citation should be written out without a number, (e.g., journal, volume, first page, and year in square brackets [Opt. Express {\bfseries 22}, 1234 (2014)]), and a separate citation should be included in the body of the text. The first reference cited in the main text must be [1]. Do not include numbers, bullets, or lists inside the abstract.
%
% \begin{figure}[h!]
% \centering\includegraphics[width=7cm]{osafig1}
% \caption{Sample caption (Fig. 2, \cite{Yelin:03}).}
% \end{figure}
%
%
% \section{Assessing final manuscript length}
% OSA's Universal Manuscript Template is based on the OSA Express layout and will provide an accurate length estimate for Optics Express, Biomedical Optics Express,  Optical Materials Express, and OSA's newest title OSA Continuum. Applied Optics, JOSAA, JOSAB, Optics Letters, Optica, and Photonics Research publish articles in a two-column layout. To estimate the final page count in a two-column layout, multiply the manuscript page count (in increments of 1/4 page) by 60\%. For example, 11.5 pages in the OSA Universal Manuscript Template are roughly equivalent to 7 composed two-column pages. Note that the estimate is only an approximation, as treatment of figure sizing, equation display, and other aspects can vary greatly across manuscripts. Authors of Letters may use the legacy template for a more accurate length estimate.
%
% \section{Figures, tables, and supplemental materials}
%
% \subsection{Figures and tables}
%
% OSA encourages authors to submit color figures with their manuscripts. Figures and tables should be placed in the body of the manuscript. Standard \LaTeX{} environments should be used to place tables and figures:
% \begin{verbatim}
% \begin{figure}[htbp]
% \centering\includegraphics[width=7cm]{osafig1}
% \caption{Sample caption (Fig. 2, \cite{Yelin:03}).}
% \end{figure}
% \end{verbatim}
%
% \subsection{Supplementary materials in OSA journals}
%
% OSA journals allow authors to include supplementary materials as integral parts of a manuscript. Such materials are subject to peer-review procedures along with the rest of the paper and should be uploaded and described using OSA's Prism manuscript system. Please see the \href{http://www.osapublishing.org/submit/style/multimedia.cfm}{Author Guidelines for Supplementary Materials in OSA Journals} for further information.
%
% Supplementary materials must be associated with a figure, table, or equation, OR be referenced in the results section of the manuscript. Please note that to create text color for supplementary materials links, use of the command \\
% \verb|\textcolor{urlblue}{Visualization 1}| is preferred to using the command\\
% \verb|\url{Visualization 1}|.
%
% \begin{figure}[ht!]
% \centering\includegraphics{osafig2}
% \caption{(a) Three traps create three rings of magnetic nanoparticles. (b) The rings interact with one another (see \textcolor{urlblue}{Visualization 1}, \cite{Masajada:13}).}
% \end{figure}
%
%
% \begin{verbatim}
% \begin{figure}[hbt!]
% \centering\includegraphics{opexfig2}
% \caption{Normalized modulus distributions of transverse electrical
% field components of the TM01 mode in PWs with (a) SiO_2 core
% and (b) Si core}{Visualization 1}), \cite{Masajada:13}).}
% \end{figure}
% \end{verbatim}
%
% \section{Mathematical and scientific notation}
%
% \subsection{Displayed equations} Displayed equations should be centered.
% Equation numbers should appear at the right-hand margin, in
% parentheses:
% \begin{equation}
% J(\rho) =
%  \frac{\gamma^2}{2} \; \sum_{k({\rm even}) = -\infty}^{\infty}
% 	\frac{(1 + k \tau)}{ \left[ (1 + k \tau)^2 + (\gamma  \rho)^2  \right]^{3/2} }.
% \end{equation}
%
% All equations should be numbered in the order in which they appear
% and should be referenced  from within the main text as Eq. (1),
% Eq. (2), and so on [or as inequality (1), etc., as appropriate].
%
%
% \section*{Funding}
% Please identify all appropriate funding sources by name and contract number. Funding information should be listed in a separate block preceding any acknowledgments. List only the funding agencies and any associated grants or project numbers, as shown in the example below:\\
% \\
% National Science Foundation (NSF) (1253236, 0868895, 1222301); Program 973 (2014AA014402); Natural National Science Foundation (NSFC) (123456).\\
% \\
% OSA participates in \href{https://www.crossref.org/fundingdata/}{Crossref's Funding Data}, a service that provides a standard way to report funding sources for published scholarly research. To ensure consistency, please enter any funding agencies and contract numbers from the Funding section in Prism during submission or revisions.
%
% \section*{Acknowledgments}
% Acknowledgments, if included, should appear at the end of the document. The section title should not be numbered.
%
% \section*{Disclosures}
% For \textit{Biomedical Optics Express} submissions only, disclosures should be listed in a separate nonnumbered section at the end of the manuscript. List the Disclosures codes identified on OSA's \href{http://www.osapublishing.org/submit/review/conflicts-interest-policy.cfm}{Conflict of Interest policy page}, as shown in the examples below:\\
% \\
% ABC: 123 Corporation (I,E,P), DEF: 456 Corporation (R,S). GHI: 789 Corporation (C).\\
% \\
% If there are no disclosures, then list ``The authors declare that there are no conflicts of interest related to this article.''
%
%
% \section{References}
% \label{sec:refs}
% Proper formatting of references is extremely important, not only for consistent appearance but also for accurate electronic tagging. Please follow the guidelines provided below on formatting, callouts, and use of Bib\TeX.
%
% \subsection{Formatting reference items}
% Each source must have its own reference number. Footnotes (notes at the bottom of text pages) are not used in OSA journals. References require all author names, full titles, and inclusive pagination. Examples of common reference types can be found on the  \href{http://www.osapublishing.org/submit/style/style_traditional_journals.cfm} {Author and Reviewer Resource Center}.
%
%
% The commands \verb+\begin{thebibliography}{}+ and \verb+\end{thebibliography}+ format the section according to standard style, showing the title {\bfseries References}.  Use the \verb+\bibitem{label}+ command to start each reference.
%
% \subsection{Formatting reference citations}
% References should be numbered consecutively in the order in which they are referenced in the body of the paper. Set reference callouts with standard \verb+\cite{}+ command or set manually inside square brackets [1].
%
% To reference multiple articles at once, simply use a comma to separate the reference labels, e.g. \verb+\cite{Yelin:03,Masajada:13,Zhang:14}+, produces \cite{Yelin:03,Masajada:13,Zhang:14}.
% %Using the \texttt{cite.sty} package will make these citations appear like so: [2--4].
%
% \subsection{Bib\TeX}
% \label{sec:bibtex}
% Bib\TeX{} may be used to create a file containing the references, whose contents (i.e., contents of \texttt{.bbl} file) can then be pasted into the bibliography section of the \texttt{.tex} file. A Bib\TeX{} style file, \texttt{osajnl.bst}, is provided.
%
% \section{Conclusion}
% After proofreading the manuscript, compress your .tex manuscript file and all figures (which should be in EPS or PDF format) in a ZIP, TAR or TAR-GZIP package. All files must be referenced at the root level (e.g., file \texttt{figure-1.eps}, not \texttt{/myfigs/figure-1.eps}). If there are supplementary materials, the associated files should not be included in your manuscript archive but be uploaded separately through the Prism interface.
%
% %%%%%%%%%%%%%%%%%%%%%%% References %%%%%%%%%%%%%%%%%%%%%%%%%
%
% Add references with BibTeX or manually.
% \cite{Zhang:14,OSA,FORSTER2007,Dean2006}
%
% %%%%%%%%%% If using BibTeX:
% \bibliography{sample}
%
% %%%%%%%%%% If preparing manually:
% % \begin{thebibliography}{1}
% % \newcommand{\enquote}[1]{``#1''}
%
% % \bibitem{Zhang:14}
% % Y.~Zhang, S.~Qiao, L.~Sun, Q.~W. Shi, W.~Huang, L.~Li, and Z.~Yang,
% %   \enquote{Photoinduced active terahertz metamaterials with nanostructured
% %   vanadium dioxide film deposited by sol-gel method,}
% %   {\protect\JournalTitle{Optics Express}} \textbf{22}, 11070--11078 (2014).
%
% % \bibitem{OSA}
% % {Optical Society}, \enquote{{OSA Publishing},}
% %   \url{http://www.osapublishing.org}.
%
% % \bibitem{FORSTER2007}
% % P.~Forster, V.~Ramaswamy, P.~Artaxo, T.~Bernsten, R.~Betts, D.~Fahey,
% %   J.~Haywood, J.~Lean, D.~Lowe, G.~Myhre, J.~Nganga, R.~Prinn, G.~Raga,
% %   M.~Schulz, and R.~V. Dorland, \enquote{Changes in atmospheric consituents and
% %   in radiative forcing,} in \enquote{Climate Change 2007: The Physical Science
% %   Basis. Contribution of Working Group 1 to the Fourth assesment report of
% %   Intergovernmental Panel on Climate Change,}  S.~Solomon, D.~Qin, M.~Manning,
% %   Z.~Chen, M.~Marquis, K.~B. Averyt, M.~Tignor, and H.~L. Miler, eds.
% %   (Cambridge University Press, 2007).
%
% % \end{thebibliography}
%
% \pagebreak
\include{supplemental}

\end{document}
